{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e5c7ca-a3f5-48bb-86de-5cad62833b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style(\"whitegrid\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "DATA_DIR = '../data'\n",
    "OUTPUT_FILE = os.path.join(DATA_DIR, 'filtered_complaints.csv')\n",
    "RAW_DATA_FILE = os.path.join(DATA_DIR, 'complaints.csv') \n",
    "\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs('reports', exist_ok=True)\n",
    "df = pd.DataFrame()\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(RAW_DATA_FILE)\n",
    "    print(f\"Successfully loaded data from {RAW_DATA_FILE}. Shape: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: {RAW_DATA_FILE} not found. Please download the CFPB complaint dataset and place it in the '{DATA_DIR}' directory.\")\n",
    "\n",
    "    exit() \n",
    "\n",
    "# --- 2. Perform an initial EDA \n",
    "print(\"\\n--- Data Overview ---\")\n",
    "print(df.info())\n",
    "print(\"\\nMissing values before preprocessing:\")\n",
    "print(df.isnull().sum()[df.isnull().sum() > 0])\n",
    "print(\"\\n--- Distribution ---\")\n",
    "product_counts = df['Product'].value_counts()\n",
    "print(product_counts)\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.barplot(y=product_counts.index, x=product_counts.values, palette='viridis')\n",
    "plt.title('Distribution of Complaints')\n",
    "plt.xlabel('Complaints number')\n",
    "plt.ylabel('Product')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "NARRATIVE_COLUMN = 'Consumer complaint narrative' #  similar\n",
    "\n",
    "if NARRATIVE_COLUMN not in df.columns:\n",
    "    print(f\"\\nWarning: Column '{NARRATIVE_COLUMN}' not found. Please check the dataset and update the NARRATIVE_COLUMN variable.\")\n",
    "    \n",
    "    if 'narrative' in df.columns:\n",
    "        NARRATIVE_COLUMN = 'narrative'\n",
    "        print(f\"Using 'narrative' column instead.\")\n",
    "    else:\n",
    "        print(\"No suitable narrative column found. Skipping narrative length analysis and filtering.\")\n",
    "        NARRATIVE_COLUMN = None # Indicate that the column is missing\n",
    "\n",
    "if NARRATIVE_COLUMN:\n",
    "    df['narrative_length'] = df[NARRATIVE_COLUMN].astype(str).apply(lambda x: len(x.split()) if pd.notna(x) else 0)\n",
    "\n",
    "    print(\"\\n--- Consumer Complaint Narrative Length Analysis ---\")\n",
    "    print(df['narrative_length'].describe())\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(df['narrative_length'], bins=50, kde=True)\n",
    "    plt.title('Distribution of Consumer Complaint Narrative Length (Word Count)')\n",
    "    plt.xlabel('Word Count')\n",
    "    plt.ylabel('Number of Complaints')\n",
    "    plt.yscale('log') # Use log scale for better visualization if there are many short narratives\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Are there very short or very long narratives?\n",
    "    print(f\"\\nNumber of narratives with less than 5 words: {df[df['narrative_length'] < 5].shape[0]}\")\n",
    "    print(f\"Number of narratives with more than 500 words: {df[df['narrative_length'] > 500].shape[0]}\")\n",
    "\n",
    "    # --- 5. Identify the number of complaints with and without narratives ---\n",
    "    num_with_narrative = df[NARRATIVE_COLUMN].notna().sum()\n",
    "    num_without_narrative = df[NARRATIVE_COLUMN].isna().sum()\n",
    "    print(f\"\\nNumber of complaints with narratives: {num_with_narrative}\")\n",
    "    print(f\"Number of complaints without narratives: {num_without_narrative}\")\n",
    "\n",
    "# --- 6. Filter the dataset to meet the project's requirements ---\n",
    "print(\"\\n--- Filtering Data ---\")\n",
    "\n",
    "# Define target products\n",
    "target_products = [\n",
    "    'Credit card',\n",
    "    'Personal loan',\n",
    "    'Buy Now, Pay Later (BNPL)', # This might need to be 'Payday loan, title loan, or personal loan' depending on CFPB's product categorization\n",
    "    'Savings account',\n",
    "    'Money transfer, virtual currency, or money service' # Often includes 'Money transfers'\n",
    "]\n",
    "\n",
    "print(\"\\nUnique products in the dataset (for reference):\")\n",
    "print(df['Product'].unique())\n",
    "\n",
    "\n",
    "actual_target_products = []\n",
    "for p in target_products:\n",
    "    if p in df['Product'].unique():\n",
    "        actual_target_products.append(p)\n",
    "    elif 'Payday loan, title loan, or personal loan' in df['Product'].unique() and 'Personal loan' in p:\n",
    "        actual_target_products.append('Payday loan, title loan, or personal loan')\n",
    "    elif 'Money transfer, virtual currency, or money service' in df['Product'].unique() and 'Money transfers' in p:\n",
    "        actual_target_products.append('Money transfer, virtual currency, or money service')\n",
    "    elif 'Checking or savings account' in df['Product'].unique() and 'Savings account' in p:\n",
    "        actual_target_products.append('Checking or savings account')\n",
    "    \n",
    "product_mapping = {\n",
    "    'Credit card': 'Credit card',\n",
    "    'Personal loan': 'Payday loan, title loan, or personal loan', # This is a common CFPB category for personal loans\n",
    "    'Buy Now, Pay Later (BNPL)': 'Credit card', # Often classified under credit cards or personal loans, or missing entirely\n",
    "    'Savings account': 'Checking or savings account',\n",
    "    'Money transfers': 'Money transfer, virtual currency, or money service'\n",
    "}\n",
    "\n",
    "# Invert and simplify mapping for filtering\n",
    "products_to_filter = []\n",
    "for requested_product, cfpb_product in product_mapping.items():\n",
    "    if cfpb_product in df['Product'].unique():\n",
    "        products_to_filter.append(cfpb_product)\n",
    "    # Special handling for BNPL if it's not a direct match in CFPB data\n",
    "    if requested_product == 'Buy Now, Pay Later (BNPL)' and 'Buy Now, Pay Later (BNPL)' not in df['Product'].unique():\n",
    "        # Check if a specific BNPL product exists, otherwise map to credit card as a fallback for the assignment\n",
    "        if 'Payday loan, title loan, or personal loan' in df['Product'].unique():\n",
    "            if 'Buy Now, Pay Later' not in products_to_filter: # Avoid duplicates\n",
    "                products_to_filter.append('Buy Now, Pay Later') # If a \"Buy Now, Pay Later\" exact product exists, use it\n",
    "        if 'Credit card' not in products_to_filter:\n",
    "            products_to_filter.append('Credit card') # As a fallback, BNPL can be treated as similar to credit card\n",
    "\n",
    "\n",
    "requested_products_exact = [\n",
    "    'Credit card',\n",
    "    'Personal loan',\n",
    "    'Buy Now, Pay Later (BNPL)',\n",
    "    'Savings account',\n",
    "    'Money transfers'\n",
    "]\n",
    "\n",
    "# Let's use a mapping for robust filtering\n",
    "product_filter_map = {\n",
    "    'Credit card': 'Credit card',\n",
    "    'Personal loan': 'Payday loan, title loan, or personal loan',\n",
    "    'Buy Now, Pay Later (BNPL)': 'Payday loan, title loan, or personal loan',\n",
    "                                                                             \n",
    "    'Savings account': 'Checking or savings account', # Most likely CFPB category\n",
    "    'Money transfers': 'Money transfer, virtual currency, or money service' # Most likely CFPB category\n",
    "}\n",
    "\n",
    "# Create a set of actual CFPB product names to filter by\n",
    "cfpb_filter_products = set()\n",
    "for requested_p in requested_products_exact:\n",
    "    if requested_p in df['Product'].unique(): # If exact match exists\n",
    "        cfpb_filter_products.add(requested_p)\n",
    "    elif requested_p in product_filter_map and product_filter_map[requested_p] in df['Product'].unique():\n",
    "        cfpb_filter_products.add(product_filter_map[requested_p])\n",
    "    else:\n",
    "        print(f\"Warning: Requested product '{requested_p}' or its mapped CFPB category not found in dataset. It will be excluded from filtering.\")\n",
    "\n",
    "print(f\"\\nFiltering for products: {list(cfpb_filter_products)}\")\n",
    "filtered_df = df[df['Product'].isin(list(cfpb_filter_products))].copy()\n",
    "print(f\"Shape after product filtering: {filtered_df.shape}\")\n",
    "\n",
    "# Remove any records with empty Consumer complaint narrative fields.\n",
    "if NARRATIVE_COLUMN:\n",
    "    initial_rows = filtered_df.shape[0]\n",
    "    filtered_df.dropna(subset=[NARRATIVE_COLUMN], inplace=True)\n",
    "    filtered_df = filtered_df[filtered_df[NARRATIVE_COLUMN].str.strip() != ''].copy() # Also remove empty strings\n",
    "    print(f\"Shape after removing empty narratives: {filtered_df.shape} (Removed {initial_rows - filtered_df.shape[0]} rows)\")\n",
    "else:\n",
    "    print(\"Skipping removal of empty narratives as narrative column was not found.\")\n",
    "\n",
    "# --- 7. Clean the text narratives to improve embedding quality ---\n",
    "print(\"\\n--- Cleaning Text Narratives ---\")\n",
    "\n",
    "if NARRATIVE_COLUMN:\n",
    "    def clean_text(text):\n",
    "        text = str(text).lower() # Lowercasing\n",
    "        text = re.sub(r'xx/xx/\\d{2,4}', ' [DATE] ', text)\n",
    "        text = re.sub(r'\\d{3,}', ' [NUMBER] ', text)\n",
    "        text = re.sub(r'x{2,}', '', text)\n",
    "        text = re.sub(r'i am writing to file a complaint', '', text, flags=re.IGNORECASE) \n",
    "        text = re.sub(r'this is a complaint regarding', '', text, flags=re.IGNORECASE) \n",
    "        text = re.sub(r'to whom it may concern', '', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r'[^a-zA-Z0-9\\s.,?!]', '', text)\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        return text\n",
    "\n",
    "    # Apply cleaning\n",
    "    filtered_df[NARRATIVE_COLUMN] = filtered_df[NARRATIVE_COLUMN].apply(clean_text)\n",
    "\n",
    "    initial_rows_after_cleaning_check = filtered_df.shape[0]\n",
    "    filtered_df['cleaned_narrative_length'] = filtered_df[NARRATIVE_COLUMN].apply(lambda x: len(x.split()) if pd.notna(x) else 0)\n",
    "    filtered_df = filtered_df[filtered_df['cleaned_narrative_length'] >= 5].copy()\n",
    "    print(f\"Shape after removing narratives too short post-cleaning: {filtered_df.shape} (Removed {initial_rows_after_cleaning_check - filtered_df.shape[0]} rows)\")\n",
    "\n",
    "    # Drop the temporary length columns\n",
    "    filtered_df.drop(columns=['narrative_length', 'cleaned_narrative_length'], errors='ignore', inplace=True)\n",
    "else:\n",
    "    print(\"Skipping text cleaning as narrative column was not found.\")\n",
    "\n",
    "if filtered_df.empty:\n",
    "    print(\"\\nWarning: The filtered dataset is empty. Check your filtering criteria and input data.\")\n",
    "else:\n",
    "    filtered_df.to_csv(OUTPUT_FILE, index=False)\n",
    "    print(f\"\\nCleaned and filtered dataset saved to {OUTPUT_FILE}\")\n",
    "    print(f\"Final dataset shape: {filtered_df.shape}\")\n",
    "    print(\"\\nSample of cleaned narratives:\")\n",
    "    print(filtered_df[NARRATIVE_COLUMN].sample(5).tolist())\n",
    "-\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
