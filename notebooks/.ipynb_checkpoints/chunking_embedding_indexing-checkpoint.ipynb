{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f612db06-2967-4bc7-bb78-2cebf581ea1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded cleaned data from ../data\\filtered_complaints.csv. Shape: (239539, 18)\n",
      "\n",
      "Sample of cleaned narratives:\n",
      "['didnt let my charges go through and cause my payment to fail.', 'on year i called capitol one to get the payoff balance and was given NUMBER .00. then i asked about the interest charges and was told i was within the time not to be charged the interest. so i paid the amount of NUMBER .00 and thought my account was paid off. i did not get the person s name. yesterday year i see i am being charged 70.00 interest charge. this morning year i called and spoke to supervisor who told me she was not able to credit the 70.00 interest charge, even though i was told i would not be charged and interest charge. she was not helpful at all. an hour later i called capitol one again and was talking to a supervisor by the name of who was quite short with me and told me she is unable to change the interest charge. when i told her i was told by a representative that i would not be charged the interest charge she was not helpful. i then asked her to speak with her supervisor and she told me their was not anyone above her. i told her i would be closing this account and again she did not care. i also told her i would be contacting cfpb and again did not care. i also told her i do not need this account i have , and and once again she did not care, so i ended the phone call. as a very good consumer i do not expect to be treated like this, nor should anyone.', 'i called wells fargo on to report my debit card had been used fraudulently and i needed to file a claim. the lady i spoke with went over everything with me and said she had opened the claim and that i would receive a temporary credit while the charges were being disputed. i was told she would sent this to the next dept and it would be one or two days for the credit. to this date ive not heard nothing or have i received a credit for the disputed transactions. it is my understanding that they have 10 days to issue a credit which is up on the but the representative should have informed me that it would be 10 days.', 'i was given a credit on my account then it was removed, causing my account to be overdrawn', 'in of NUMBER i got a loan for solar panels to be installed by to be put on the house and financed through . three months went by and never finished the installation. after another two months went by with extended attempts to contact they never returned any calls or emails to finish installation. by this time my payments to were first due in of NUMBER , after multiple attempts to explain to that the solar panels were not finished installed and or operational. informed me that was paid in full and i was required to pay my loan even though the panels werent working. dipersed funds to without confirming that the solar panels were fully installed and operational. has since filled for bankruptcy and is under a class action suit from the arkansas attorney general file . also filled a complaint to the case']\n"
     ]
    }
   ],
   "source": [
    "# notebooks/task_2_chunking_embedding_indexing_chromadb.ipynb\n",
    "import pandas as pd\n",
    "import os\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma # <--- THIS LINE IS CRUCIAL\n",
    "from langchain_core.documents import Document\n",
    "from chromadb.config import Settings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "!pip install -qU numpy==1.26.4\n",
    "\n",
    "# --- Configuration ---\n",
    "DATA_DIR = '../data'\n",
    "VECTOR_STORE_DIR = '../vector_store'\n",
    "FILTERED_DATA_FILE = os.path.join(DATA_DIR, 'filtered_complaints.csv')\n",
    "CHROMA_PERSIST_DIR = os.path.join(VECTOR_STORE_DIR, 'chroma_db_credi_trust')\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs(VECTOR_STORE_DIR, exist_ok=True)\n",
    "\n",
    "# Load the cleaned and filtered dataset from Task 1\n",
    "try:\n",
    "    df_cleaned = pd.read_csv(FILTERED_DATA_FILE)\n",
    "    print(f\"Successfully loaded cleaned data from {FILTERED_DATA_FILE}. Shape: {df_cleaned.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: {FILTERED_DATA_FILE} not found. Please ensure Task 1 was completed and the file exists.\")\n",
    "    exit()\n",
    "\n",
    "# Identify the narrative column (assuming it's 'Consumer complaint narrative' from Task 1)\n",
    "NARRATIVE_COLUMN = 'Consumer complaint narrative'\n",
    "if NARRATIVE_COLUMN not in df_cleaned.columns:\n",
    "    print(f\"Error: '{NARRATIVE_COLUMN}' not found in the loaded DataFrame. Please check the column name.\")\n",
    "    exit()\n",
    "\n",
    "# Display a sample of the cleaned narratives\n",
    "print(\"\\nSample of cleaned narratives:\")\n",
    "print(df_cleaned[NARRATIVE_COLUMN].sample(5).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33b76826-febf-49db-90e5-d1c5787e6d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Applying Text Chunking Strategy ---\n",
      "\n",
      "Total number of documents (chunks) created: 730562\n",
      "First chunk example:\n",
      "Content: a card was opened under my name by a fraudster. i received a notice from that an account was just opened under my name. i reached out to to state that this activity was unauthorized and not me. confirmed this was fraudulent and immediately closed the card. however, they have failed to remove this from the three credit agencies and this fraud is now impacting my credit score based on a hard credit pull done by that was done by a fraudster.\n",
      "Metadata: {'complaint_id': '14069121', 'product': 'Credit card', 'chunk_id': 0, 'original_index': 0}\n",
      "Second chunk example:\n",
      "Content: i made the mistake of using my wellsfargo debit card to depsit funds into atm machine outside their branch. i went into the branch and was told they couldnt help and had to phone the customer service for help. i did this and was told i was helped gave all the info for the time terminal id aact s, was able to find the transaction and give me this info, he said the dispute would take a few days. i waited a few days and got a letter stating my dispute was rejected. i went back into and they said\n",
      "Metadata: {'complaint_id': '14061897', 'product': 'Checking or savings account', 'chunk_id': 0, 'original_index': 1}\n",
      "\n",
      "Justification for Chunking Strategy (for your report):\n",
      "Chosen chunk_size: 500 characters.\n",
      "Chosen chunk_overlap: 100 characters.\n",
      "This strategy aims to create chunks that are sufficiently large to encapsulate meaningful context related to a complaint, while remaining small enough for efficient embedding and retrieval. The overlap is crucial to prevent the loss of context that might occur at chunk boundaries, thereby improving the chances of retrieving relevant information even if it spans across two separate chunks.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Applying Text Chunking Strategy ---\")\n",
    "\n",
    "FINAL_CHUNK_SIZE = 500\n",
    "FINAL_CHUNK_OVERLAP = 100\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=FINAL_CHUNK_SIZE,\n",
    "    chunk_overlap=FINAL_CHUNK_OVERLAP,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "# Prepare documents with metadata for ChromaDB\n",
    "documents = []\n",
    "for index, row in df_cleaned.iterrows():\n",
    "    text = row[NARRATIVE_COLUMN]\n",
    "    if pd.notna(text) and text.strip() != '':\n",
    "        chunks = text_splitter.split_text(text)\n",
    "        for i, chunk_content in enumerate(chunks):\n",
    "            documents.append(Document(\n",
    "                page_content=chunk_content,\n",
    "                metadata={\n",
    "                    \"complaint_id\": str(row['Complaint ID']) if 'Complaint ID' in row else str(index), # Ensure ID is string\n",
    "                    \"product\": row['Product'],\n",
    "                    \"chunk_id\": i,\n",
    "                    \"original_index\": index # To trace back to original DataFrame row\n",
    "                }\n",
    "            ))\n",
    "\n",
    "print(f\"\\nTotal number of documents (chunks) created: {len(documents)}\")\n",
    "if documents:\n",
    "    print(f\"First chunk example:\\nContent: {documents[0].page_content}\\nMetadata: {documents[0].metadata}\")\n",
    "    print(f\"Second chunk example:\\nContent: {documents[1].page_content}\\nMetadata: {documents[1].metadata}\")\n",
    "\n",
    "# Justification for Chunking Strategy (for your report)\n",
    "print(f\"\\nJustification for Chunking Strategy (for your report):\")\n",
    "print(f\"Chosen chunk_size: {FINAL_CHUNK_SIZE} characters.\")\n",
    "print(f\"Chosen chunk_overlap: {FINAL_CHUNK_OVERLAP} characters.\")\n",
    "print(f\"This strategy aims to create chunks that are sufficiently large to encapsulate meaningful context related to a complaint, while remaining small enough for efficient embedding and retrieval. The overlap is crucial to prevent the loss of context that might occur at chunk boundaries, thereby improving the chances of retrieving relevant information even if it spans across two separate chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6be42565-18dd-4522-b83f-b00627593cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Choosing Embedding Model ---\n",
      "Chosen embedding model: sentence-transformers/all-MiniLM-L6-v2\n",
      "Brief explanation for model choice:\n",
      "The 'sentence-transformers/all-MiniLM-L6-v2' model was selected due to its proven balance of computational efficiency and semantic accuracy. It excels at generating high-quality sentence embeddings, which are vital for effective semantic search in the context of customer complaints. Its relatively small size (384-dimensional embeddings) and fast inference speed make it ideal for an internal AI tool that requires quick processing of large volumes of text data without significant hardware overhead. This model effectively captures the nuanced meaning of sentences and short paragraphs, which is essential for identifying subtle complaint trends.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Choosing Embedding Model ---\")\n",
    "# Initialize the embedding model\n",
    "# i use HuggingFaceEmbeddings which is a convenient wrapper for sentence-transformers models\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=model_name)\n",
    "\n",
    "print(f\"Chosen embedding model: {model_name}\")\n",
    "print(f\"Brief explanation for model choice:\")\n",
    "print(f\"The 'sentence-transformers/all-MiniLM-L6-v2' model was selected due to its proven balance of computational efficiency and semantic accuracy. It excels at generating high-quality sentence embeddings, which are vital for effective semantic search in the context of customer complaints. Its relatively small size (384-dimensional embeddings) and fast inference speed make it ideal for an internal AI tool that requires quick processing of large volumes of text data without significant hardware overhead. This model effectively captures the nuanced meaning of sentences and short paragraphs, which is essential for identifying subtle complaint trends.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "908015af-92cf-41de-91f2-c3b355ac802e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Creating and Persisting ChromaDB Vector Store ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromaDB index persisted locally to: ../vector_store\\chroma_db_credi_trust\n",
      "\n",
      "Loading the persisted ChromaDB index for verification...\n",
      "ChromaDB index loaded successfully from disk.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 results for query: 'unauthorized transactions on my credit card'\n",
      "\n",
      "--- Result 1 ---\n",
      "Content (first 200 chars): i been having unauthorized transactions in my card this is not the first time they never do a full investigation and never send me the info after i request it...\n",
      "Metadata: {'chunk_id': 0, 'complaint_id': '12565625', 'original_index': 16676, 'product': 'Checking or savings account'}\n",
      "Source Complaint ID: 12565625\n",
      "Product: Checking or savings account\n",
      "Chunk ID: 0\n",
      "\n",
      "--- Result 2 ---\n",
      "Content (first 200 chars): i have had several problems with unauthorized transactions on my checking account. i have purchased a special wallet to deflect thieves and carry large amounts of cash to decrease my card use finally,...\n",
      "Metadata: {'chunk_id': 0, 'complaint_id': '9985031', 'original_index': 23460, 'product': 'Checking or savings account'}\n",
      "Source Complaint ID: 9985031\n",
      "Product: Checking or savings account\n",
      "Chunk ID: 0\n",
      "\n",
      "--- Result 3 ---\n",
      "Content (first 200 chars): earlier this month there were several unauthorized transactions on my . these transactions where from the company . i do not have an account with this company, and have done no transactions whatsoever...\n",
      "Metadata: {'chunk_id': 0, 'complaint_id': '11841844', 'original_index': 16001, 'product': 'Checking or savings account'}\n",
      "Source Complaint ID: 11841844\n",
      "Product: Checking or savings account\n",
      "Chunk ID: 0\n",
      "\n",
      "--- Result 4 ---\n",
      "Content (first 200 chars): containing various cards and identification. despite my condition, i promptly notified all relevant financial institutions, including customer service, about the loss of my cards. unauthorized charges...\n",
      "Metadata: {'chunk_id': 1, 'complaint_id': '11682235', 'original_index': 25387, 'product': 'Credit card'}\n",
      "Source Complaint ID: 11682235\n",
      "Product: Credit card\n",
      "Chunk ID: 1\n",
      "\n",
      "--- Result 5 ---\n",
      "Content (first 200 chars): i called my financial institution immediately after i noticed several unauthorized purchases on my account. while on the phone with the fraud department there was more transactions from the same merch...\n",
      "Metadata: {'chunk_id': 0, 'complaint_id': '8273419', 'original_index': 14779, 'product': 'Checking or savings account'}\n",
      "Source Complaint ID: 8273419\n",
      "Product: Checking or savings account\n",
      "Chunk ID: 0\n",
      "\n",
      "Task 2: Text Chunking, Embedding, and Vector Store Indexing (with ChromaDB) completed.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Creating and Persisting ChromaDB Vector Store ---\")\n",
    "from chromadb.config import Settings  # Import Settings from chromadb.config\n",
    "\n",
    "chroma_client_settings = Settings(\n",
    "    anonymized_telemetry=False,\n",
    ")\n",
    "\n",
    "try:\n",
    "    # Initialize Chroma with the embedding function and persistence directory\n",
    "    vector_store = Chroma.from_documents(\n",
    "        documents=documents,\n",
    "        embedding=embedding_model,\n",
    "        persist_directory=CHROMA_PERSIST_DIR,\n",
    "        collection_name=\"credi_trust_complaints\",\n",
    "        client_settings=chroma_client_settings  # <--- ADD THIS LINE\n",
    "    )\n",
    "\n",
    "    # You explicitly call persist() to write the data to disk in ChromaDB\n",
    "    vector_store.persist()\n",
    "    print(f\"ChromaDB index persisted locally to: {CHROMA_PERSIST_DIR}\")\n",
    "\n",
    "    # Optional: Load and test the persisted store\n",
    "    print(\"\\nLoading the persisted ChromaDB index for verification...\")\n",
    "    loaded_vector_store = Chroma(\n",
    "        persist_directory=CHROMA_PERSIST_DIR,\n",
    "        embedding_function=embedding_model,\n",
    "        collection_name=\"credi_trust_complaints\"\n",
    "    )\n",
    "    print(\"ChromaDB index loaded successfully from disk.\")\n",
    "\n",
    "    # Test a similarity search\n",
    "    query = \"unauthorized transactions on my credit card\"\n",
    "    results = loaded_vector_store.similarity_search(query, k=5)  # Retrieve top 5 similar documents\n",
    "\n",
    "    print(f\"\\nTop 5 results for query: '{query}'\")\n",
    "    for i, doc in enumerate(results):\n",
    "        print(f\"\\n--- Result {i + 1} ---\")\n",
    "        print(f\"Content (first 200 chars): {doc.page_content[:200]}...\")\n",
    "        print(f\"Metadata: {doc.metadata}\")\n",
    "        print(f\"Source Complaint ID: {doc.metadata.get('complaint_id')}\")\n",
    "        print(f\"Product: {doc.metadata.get('product')}\")\n",
    "        print(f\"Chunk ID: {doc.metadata.get('chunk_id')}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during ChromaDB vector store creation or saving: {e}\")\n",
    "\n",
    "print(\"\\nTask 2: Text Chunking, Embedding, and Vector Store Indexing (with ChromaDB) completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e212e00-7edc-4ac3-89cd-b3fa7ac6f276",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
