{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9100058264f84e7393476f8b6a534bfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_387cbaa7d61649c7908e01eea09c5e89",
              "IPY_MODEL_8c6771855a32422b91fa5e3d79beb77d",
              "IPY_MODEL_1f27f86c9402404a8c0a7b2f96213163"
            ],
            "layout": "IPY_MODEL_3d6ef9e140dc44c8bbfc9e5e6fb3168c"
          }
        },
        "387cbaa7d61649c7908e01eea09c5e89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cef3c6849eaa44a08d6e93a49d8ffe71",
            "placeholder": "​",
            "style": "IPY_MODEL_9c853b6bb0d4446e9e7fb8f5e58c2394",
            "value": "model.safetensors: 100%"
          }
        },
        "8c6771855a32422b91fa5e3d79beb77d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43c7c43105dd41bd99125e0812639c43",
            "max": 307867048,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf5199d9823e46e983694ea164ae7f0e",
            "value": 307867048
          }
        },
        "1f27f86c9402404a8c0a7b2f96213163": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48b9ace4e93f44c1a3336dfdd1f2d8ac",
            "placeholder": "​",
            "style": "IPY_MODEL_a4f433094f3c49c9806afd00912e7eb4",
            "value": " 308M/308M [00:07&lt;00:00, 41.9MB/s]"
          }
        },
        "3d6ef9e140dc44c8bbfc9e5e6fb3168c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cef3c6849eaa44a08d6e93a49d8ffe71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c853b6bb0d4446e9e7fb8f5e58c2394": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43c7c43105dd41bd99125e0812639c43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf5199d9823e46e983694ea164ae7f0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "48b9ace4e93f44c1a3336dfdd1f2d8ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4f433094f3c49c9806afd00912e7eb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "080e3ae4a6a04b0895ca04ce618db445": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_84b6a69a626d400e97588e5b120debc6",
              "IPY_MODEL_11527b9e366d4f1b9de65ba4be53a992",
              "IPY_MODEL_05d0ab3e49be410eb6632c41847bcdcc"
            ],
            "layout": "IPY_MODEL_58dadff2b011400c8bf027456cc7aa21"
          }
        },
        "84b6a69a626d400e97588e5b120debc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8b95588e44c4e5cb734c83a0ad7a812",
            "placeholder": "​",
            "style": "IPY_MODEL_f5b4bdee011142658f8b4ff8a1d5e706",
            "value": "generation_config.json: 100%"
          }
        },
        "11527b9e366d4f1b9de65ba4be53a992": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfed5df19bdc44b091afdbeb8bb5e90a",
            "max": 147,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_351cc92ee2ad46c380a3a6b9a24d7789",
            "value": 147
          }
        },
        "05d0ab3e49be410eb6632c41847bcdcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_029629a10e014d9899a59d6225b0505e",
            "placeholder": "​",
            "style": "IPY_MODEL_a069bcc0fb2645baaf11054c9578cbc2",
            "value": " 147/147 [00:00&lt;00:00, 9.94kB/s]"
          }
        },
        "58dadff2b011400c8bf027456cc7aa21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8b95588e44c4e5cb734c83a0ad7a812": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5b4bdee011142658f8b4ff8a1d5e706": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfed5df19bdc44b091afdbeb8bb5e90a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "351cc92ee2ad46c380a3a6b9a24d7789": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "029629a10e014d9899a59d6225b0505e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a069bcc0fb2645baaf11054c9578cbc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99n6ialP9VGr",
        "outputId": "ca77deb0-115c-4e53-b32d-79c21ba8b734"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Uninstalling existing versions to ensure a clean slate...\n",
            "Found existing installation: torch 2.6.0+cu124\n",
            "Uninstalling torch-2.6.0+cu124:\n",
            "  Successfully uninstalled torch-2.6.0+cu124\n",
            "Found existing installation: torchvision 0.21.0+cu124\n",
            "Uninstalling torchvision-0.21.0+cu124:\n",
            "  Successfully uninstalled torchvision-0.21.0+cu124\n",
            "Found existing installation: torchaudio 2.6.0+cu124\n",
            "Uninstalling torchaudio-2.6.0+cu124:\n",
            "  Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "Found existing installation: numpy 2.0.2\n",
            "Uninstalling numpy-2.0.2:\n",
            "  Successfully uninstalled numpy-2.0.2\n",
            "Found existing installation: transformers 4.53.0\n",
            "Uninstalling transformers-4.53.0:\n",
            "  Successfully uninstalled transformers-4.53.0\n",
            "Found existing installation: accelerate 1.8.1\n",
            "Uninstalling accelerate-1.8.1:\n",
            "  Successfully uninstalled accelerate-1.8.1\n",
            "Found existing installation: safetensors 0.5.3\n",
            "Uninstalling safetensors-0.5.3:\n",
            "  Successfully uninstalled safetensors-0.5.3\n",
            "Found existing installation: tokenizers 0.21.2\n",
            "Uninstalling tokenizers-0.21.2:\n",
            "  Successfully uninstalled tokenizers-0.21.2\n",
            "Found existing installation: sentencepiece 0.2.0\n",
            "Uninstalling sentencepiece-0.2.0:\n",
            "  Successfully uninstalled sentencepiece-0.2.0\n",
            "Found existing installation: packaging 24.2\n",
            "Uninstalling packaging-24.2:\n",
            "  Successfully uninstalled packaging-24.2\n",
            "Found existing installation: langchain 0.3.26\n",
            "Uninstalling langchain-0.3.26:\n",
            "  Successfully uninstalled langchain-0.3.26\n",
            "\u001b[33mWARNING: Skipping langchain_community as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping chromadb as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: h5py 3.14.0\n",
            "Uninstalling h5py-3.14.0:\n",
            "  Successfully uninstalled h5py-3.14.0\n",
            "Found existing installation: sentence-transformers 4.1.0\n",
            "Uninstalling sentence-transformers-4.1.0:\n",
            "  Successfully uninstalled sentence-transformers-4.1.0\n",
            "\n",
            "Installing latest versions of core libraries, allowing pip to resolve for NumPy 2.x...\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.5/780.5 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.19 requires packaging, which is not installed.\n",
            "geopandas 1.0.1 requires packaging, which is not installed.\n",
            "shap 0.48.0 requires packaging>20.9, which is not installed.\n",
            "cudf-cu12 25.2.1 requires packaging, which is not installed.\n",
            "torchtune 0.6.1 requires safetensors, which is not installed.\n",
            "torchtune 0.6.1 requires sentencepiece, which is not installed.\n",
            "torchtune 0.6.1 requires tokenizers, which is not installed.\n",
            "arviz 0.21.0 requires packaging, which is not installed.\n",
            "bokeh 3.7.3 requires packaging>=16.8, which is not installed.\n",
            "pandas-gbq 0.29.1 requires packaging>=22.0.0, which is not installed.\n",
            "thinc 8.3.6 requires packaging>=20.0, which is not installed.\n",
            "peft 0.15.2 requires accelerate>=0.21.0, which is not installed.\n",
            "peft 0.15.2 requires packaging>=20.0, which is not installed.\n",
            "peft 0.15.2 requires safetensors, which is not installed.\n",
            "peft 0.15.2 requires transformers, which is not installed.\n",
            "pyogrio 0.11.0 requires packaging, which is not installed.\n",
            "xarray 2025.3.1 requires packaging>=23.2, which is not installed.\n",
            "matplotlib 3.10.0 requires packaging>=20.0, which is not installed.\n",
            "datasets 2.14.4 requires packaging, which is not installed.\n",
            "scikit-image 0.25.2 requires packaging>=21, which is not installed.\n",
            "bigquery-magics 0.9.0 requires packaging>=20.0.0, which is not installed.\n",
            "diffusers 0.34.0 requires safetensors>=0.3.1, which is not installed.\n",
            "treelite 4.4.1 requires packaging, which is not installed.\n",
            "db-dtypes 1.4.3 requires packaging>=24.2.0, which is not installed.\n",
            "cuml-cu12 25.2.1 requires packaging, which is not installed.\n",
            "keras 3.8.0 requires h5py, which is not installed.\n",
            "keras 3.8.0 requires packaging, which is not installed.\n",
            "pylibcudf-cu12 25.2.1 requires packaging, which is not installed.\n",
            "spacy 3.8.7 requires packaging>=20.0, which is not installed.\n",
            "tables 3.10.2 requires packaging, which is not installed.\n",
            "libpysal 4.13.0 requires packaging>=22, which is not installed.\n",
            "keras-hub 0.18.1 requires packaging, which is not installed.\n",
            "timm 1.0.16 requires safetensors, which is not installed.\n",
            "statsmodels 0.14.4 requires packaging>=21.3, which is not installed.\n",
            "tensorboard 2.18.0 requires packaging, which is not installed.\n",
            "gradio 5.31.0 requires packaging, which is not installed.\n",
            "holoviews 1.21.0 requires packaging, which is not installed.\n",
            "nibabel 5.3.2 requires packaging>=20, which is not installed.\n",
            "astropy 7.1.0 requires packaging>=22.0.0, which is not installed.\n",
            "tensorflow 2.18.0 requires h5py>=3.11.0, which is not installed.\n",
            "tensorflow 2.18.0 requires packaging, which is not installed.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.1.2 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.3/365.3 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m470.2/470.2 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m90.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m96.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.2/71.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtune 0.6.1 requires sentencepiece, which is not installed.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Cell 1: Initial setup - Mount Drive, Install Libraries, Force Restart\n",
        "# *** IMPORTANT: Run this as your FIRST cell after \"Disconnect and delete runtime\" and reconnecting ***\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(\"Uninstalling existing versions to ensure a clean slate...\")\n",
        "# Uninstall all related packages comprehensively.\n",
        "!pip uninstall -y torch torchvision torchaudio numpy transformers accelerate safetensors tokenizers sentencepiece packaging langchain langchain_community chromadb h5py sentence_transformers\n",
        "\n",
        "print(\"\\nInstalling latest versions of core libraries, allowing pip to resolve for NumPy 2.x...\")\n",
        "\n",
        "# Install PyTorch for Colab's CUDA version.\n",
        "# For recent Colab, cu121 (CUDA 12.1) is common.\n",
        "!pip install -qU torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "# Install latest versions of other libraries.\n",
        "# The -U flag ensures upgrade, and -q keeps output quiet.\n",
        "# Let pip resolve dependencies to the latest compatible versions.\n",
        "!pip install -qU transformers accelerate sentence-transformers langchain langchain_community chromadb h5py packaging\n",
        "\n",
        "# --- Verification of installed versions (now safe to import after installation) ---\n",
        "import torch\n",
        "import numpy as np\n",
        "try:\n",
        "    import transformers\n",
        "    import accelerate\n",
        "    import sentence_transformers\n",
        "    import langchain\n",
        "    import packaging\n",
        "except ImportError as e:\n",
        "    print(f\"Error importing modules for verification (this might happen before restart): {e}\")\n",
        "\n",
        "print(f\"\\nPyTorch CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"PyTorch CUDA version: {torch.version.cuda}\")\n",
        "print(f\"NVIDIA GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'N/A'}\")\n",
        "print(f\"Installed torch version: {torch.__version__}\")\n",
        "print(f\"Installed numpy version: {np.__version__}\")\n",
        "if 'transformers' in locals():\n",
        "    print(f\"Installed transformers version: {transformers.__version__}\")\n",
        "if 'accelerate' in locals():\n",
        "    print(f\"Installed accelerate version: {accelerate.__version__}\")\n",
        "if 'sentence_transformers' in locals():\n",
        "    print(f\"Installed sentence-transformers version: {sentence_transformers.__version__}\")\n",
        "if 'langchain' in locals():\n",
        "    print(f\"Installed langchain version: {langchain.__version__}\")\n",
        "if 'packaging' in locals():\n",
        "    print(f\"Installed packaging version: {packaging.__version__}\")\n",
        "# --- End Verification ---\n",
        "\n",
        "print(\"\\nInitial installations complete. Forcing runtime restart to apply all changes.\")\n",
        "import os\n",
        "os._exit(0) # This will crash the runtime."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Main RAG Code (run this *after* Cell 1 has crashed and you've restarted the session)\n",
        "\n",
        "# Re-mount Google Drive (essential after any restart/reset)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Now, import the libraries (they should now be correctly installed and available)\n",
        "import os\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_community.llms import HuggingFacePipeline\n",
        "# CORRECTED IMPORT: Use AutoModelForSeq2SeqLM for T5 models\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM, AutoModelForSeq2SeqLM\n",
        "import torch\n",
        "import pandas as pd\n",
        "import warnings\n",
        "import numpy as np\n",
        "\n",
        "warnings.filterwarnings('ignore') # Suppress warnings\n",
        "\n",
        "# --- Verification of imported versions ---\n",
        "try:\n",
        "    import accelerate\n",
        "    import transformers\n",
        "    import sentence_transformers\n",
        "    import langchain\n",
        "    import packaging\n",
        "    print(f\"\\nChecking imported transformers version: {transformers.__version__}\")\n",
        "    print(f\"Checking imported accelerate version: {accelerate.__version__}\")\n",
        "    print(f\"Checking imported torch version: {torch.__version__}\")\n",
        "    print(f\"Checking imported numpy version: {np.__version__}\")\n",
        "    print(f\"Checking imported langchain version: {langchain.__version__}\")\n",
        "    print(f\"Checking imported packaging version: {packaging.__version__}\")\n",
        "\n",
        "except ImportError as e:\n",
        "    print(f\"Critical Error: Failed to import necessary libraries after restart: {e}\")\n",
        "    print(\"Please ensure Cell 1 ran successfully and the runtime was restarted.\")\n",
        "    exit()\n",
        "\n",
        "# --- Configuration ---\n",
        "DATA_DIR = '/content/drive/MyDrive/'\n",
        "VECTOR_STORE_DIR = '/content/drive/MyDrive/vector_store'\n",
        "CHROMA_PERSIST_DIR = os.path.join(VECTOR_STORE_DIR, 'chroma_db_credi_trust')\n",
        "EMBEDDING_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "LLM_MODEL_NAME = \"google/flan-t5-small\"\n",
        "\n",
        "# --- 1. Retriever Implementation ---\n",
        "\n",
        "print(f\"Loading embedding model: {EMBEDDING_MODEL_NAME}...\")\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL_NAME)\n",
        "print(\"Embedding model loaded.\")\n",
        "\n",
        "# Load the persisted ChromaDB vector store\n",
        "print(f\"Loading ChromaDB from: {CHROMA_PERSIST_DIR}...\")\n",
        "try:\n",
        "    vector_store = Chroma(\n",
        "        persist_directory=CHROMA_PERSIST_DIR,\n",
        "        embedding_function=embedding_model,\n",
        "        collection_name=\"credi_trust_complaints\"\n",
        "    )\n",
        "    print(\"ChromaDB vector store loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading ChromaDB: {e}\")\n",
        "    print(\"Please ensure the persist_directory and collection_name are correct and the database was saved properly in Task 2.\")\n",
        "    vector_store = None\n",
        "\n",
        "def retrieve_chunks(question: str, vector_store: Chroma, k: int = 5):\n",
        "    if vector_store is None:\n",
        "        print(\"Error: Vector store not loaded. Cannot retrieve chunks.\")\n",
        "        return []\n",
        "    print(f\"\\nRetrieving top {k} chunks for query: '{question}'...\")\n",
        "    # CORRECTED TYPO: .similarity_search instead of .similarity.search\n",
        "    retrieved_docs = vector_store.similarity_search(question, k=k)\n",
        "    print(f\"Retrieved {len(retrieved_docs)} chunks.\")\n",
        "    return retrieved_docs\n",
        "\n",
        "# --- 2. Prompt Engineering ---\n",
        "\n",
        "prompt_template_str = \"\"\"\n",
        "You are a financial analyst assistant for CrediTrust. Your task is to answer questions about customer complaints.\n",
        "Use the following retrieved complaint excerpts to formulate your answer.\n",
        "If the context doesn't contain the answer, state that you don't have enough information.\n",
        "Be concise and directly answer the question based *only* on the provided context.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "PROMPT = PromptTemplate(template=prompt_template_str, input_variables=[\"context\", \"question\"])\n",
        "print(\"\\nPrompt template defined.\")\n",
        "\n",
        "# --- 3. Generator Implementation ---\n",
        "\n",
        "print(f\"\\nLoading LLM: {LLM_MODEL_NAME}...\")\n",
        "try:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(LLM_MODEL_NAME)\n",
        "\n",
        "    if \"t5\" in LLM_MODEL_NAME.lower():\n",
        "        # CORRECTED MODEL CLASS: Use AutoModelForSeq2SeqLM for T5\n",
        "        model = AutoModelForSeq2SeqLM.from_pretrained(LLM_MODEL_NAME, torch_dtype=torch.float32, device_map=\"auto\")\n",
        "        pipe = pipeline(\n",
        "            \"text2text-generation\", # T5 uses text2text-generation\n",
        "            model=model,\n",
        "            tokenizer=tokenizer,\n",
        "            max_new_tokens=256,\n",
        "            do_sample=True,\n",
        "            temperature=0.7,\n",
        "            top_p=0.95,\n",
        "            repetition_penalty=1.1,\n",
        "            pad_token_id=tokenizer.pad_token_id if tokenizer.pad_token_id is not None else tokenizer.eos_token_id,\n",
        "        )\n",
        "    else:\n",
        "        # Keep AutoModelForCausalLM for other model types if you change LLM_MODEL_NAME later\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            LLM_MODEL_NAME,\n",
        "            torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n",
        "            device_map=\"auto\"\n",
        "        )\n",
        "        pipe = pipeline(\n",
        "            \"text-generation\", # Causal models use text-generation\n",
        "            model=model,\n",
        "            tokenizer=tokenizer,\n",
        "            max_new_tokens=256,\n",
        "            do_sample=True,\n",
        "            temperature=0.7,\n",
        "            top_p=0.95,\n",
        "            repetition_penalty=1.1,\n",
        "            eos_token_id=tokenizer.eos_token_id,\n",
        "            pad_token_id=tokenizer.pad_token_id if tokenizer.pad_token_id is not None else tokenizer.eos_token_id,\n",
        "        )\n",
        "\n",
        "    llm = HuggingFacePipeline(pipeline=pipe)\n",
        "    print(f\"LLM '{LLM_MODEL_NAME}' loaded successfully.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading LLM: {e}\")\n",
        "    print(\"Please check the LLM_MODEL_NAME and ensure you have sufficient resources (GPU/RAM) if using a large model.\")\n",
        "    llm = None\n",
        "\n",
        "def generate_answer(question: str, retrieved_docs: list, llm: HuggingFacePipeline):\n",
        "    if llm is None:\n",
        "        return \"Error: Language model not loaded. Cannot generate answer.\"\n",
        "\n",
        "    context_text = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
        "    formatted_prompt = PROMPT.format(context=context_text, question=question)\n",
        "\n",
        "    print(\"\\nSending formatted prompt to LLM...\")\n",
        "    response = llm.invoke(formatted_prompt)\n",
        "\n",
        "    if isinstance(response, list) and len(response) > 0 and 'generated_text' in response[0]:\n",
        "        generated_text = response[0]['generated_text']\n",
        "        # Remove the prompt itself from the generated text if the model echoes it\n",
        "        if formatted_prompt in generated_text:\n",
        "            generated_text = generated_text[generated_text.find(formatted_prompt) + len(formatted_prompt):].strip()\n",
        "        # Remove \"Answer:\" prefix if present\n",
        "        if generated_text.startswith(\"Answer:\"):\n",
        "            generated_text = generated_text[len(\"Answer:\"):].strip()\n",
        "        return generated_text\n",
        "    elif isinstance(response, str):\n",
        "        return response.strip()\n",
        "    else:\n",
        "        print(f\"Unexpected LLM response format: {response}\")\n",
        "        return \"Could not generate a coherent answer.\"\n",
        "\n",
        "\n",
        "# --- 4. Qualitative Evaluation ---\n",
        "\n",
        "print(\"\\n--- Starting Qualitative Evaluation ---\")\n",
        "\n",
        "evaluation_questions = [\n",
        "    \"What are common complaints related to credit cards?\",\n",
        "    \"Tell me about issues with personal loans.\",\n",
        "    \"Are there any complaints about money transfers being delayed?\",\n",
        "    \"What problems do consumers face with Buy Now, Pay Later services?\",\n",
        "    \"Describe typical complaints about savings accounts.\",\n",
        "    \"A customer reported a fraudulent charge on their card. What product is this related to?\",\n",
        "    \"I sent money to a wrong account. What product category would this fall under?\",\n",
        "    \"What is a common issue with interest rates on personal loans?\",\n",
        "    \"Are there any complaints about account closures for savings accounts?\",\n",
        "    \"What are the main concerns regarding BNPL late fees?\"\n",
        "]\n",
        "\n",
        "evaluation_results = []\n",
        "\n",
        "for i, question in enumerate(evaluation_questions):\n",
        "    print(f\"\\n--- Evaluating Question {i+1}: {question} ---\")\n",
        "    retrieved_docs = retrieve_chunks(question, vector_store, k=5)\n",
        "\n",
        "    sources_info = []\n",
        "    for doc in retrieved_docs:\n",
        "        sources_info.append(\n",
        "            f\"Source (Complaint ID: {doc.metadata.get('complaint_id', 'N/A')}, \"\n",
        "            f\"Product: {doc.metadata.get('product', 'N/A')}):\\n\"\n",
        "            f\"{doc.page_content[:150]}...\"\n",
        "        )\n",
        "\n",
        "    generated_answer = generate_answer(question, retrieved_docs, llm)\n",
        "\n",
        "    evaluation_results.append({\n",
        "        \"Question\": question,\n",
        "        \"Generated Answer\": generated_answer,\n",
        "        \"Retrieved Sources\": sources_info[:2],\n",
        "        \"Quality Score\": \" (Manual 1-5)\",\n",
        "        \"Comments/Analysis\": \" (Manual analysis)\"\n",
        "    })\n",
        "\n",
        "    print(f\"\\nGenerated Answer: {generated_answer}\")\n",
        "    print(f\"\\nTop Retrieved Sources (for analysis):\")\n",
        "    for src in sources_info[:2]:\n",
        "        print(src)\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "print(\"\\n--- Evaluation Table (Copy this to your report and fill in scores/comments) ---\")\n",
        "print(\"| Question | Generated Answer | Retrieved Sources (top 2) | Quality Score (1-5) | Comments/Analysis |\")\n",
        "print(\"|----------|------------------|---------------------------|---------------------|-------------------|\")\n",
        "for result in evaluation_results:\n",
        "    formatted_sources = \"<br>\".join(result['Retrieved Sources'])\n",
        "    answer_for_md = result['Generated Answer'].replace('|', '\\|')\n",
        "    sources_for_md = formatted_sources.replace('|', '\\|')\n",
        "\n",
        "    print(f\"| {result['Question']} | {answer_for_md} | {sources_for_md} | {result['Quality Score']} | {result['Comments/Analysis']} |\")\n",
        "\n",
        "print(\"\\nTask 3: RAG Core Logic and Evaluation completed. Please manually fill the evaluation table in your report.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9100058264f84e7393476f8b6a534bfc",
            "387cbaa7d61649c7908e01eea09c5e89",
            "8c6771855a32422b91fa5e3d79beb77d",
            "1f27f86c9402404a8c0a7b2f96213163",
            "3d6ef9e140dc44c8bbfc9e5e6fb3168c",
            "cef3c6849eaa44a08d6e93a49d8ffe71",
            "9c853b6bb0d4446e9e7fb8f5e58c2394",
            "43c7c43105dd41bd99125e0812639c43",
            "bf5199d9823e46e983694ea164ae7f0e",
            "48b9ace4e93f44c1a3336dfdd1f2d8ac",
            "a4f433094f3c49c9806afd00912e7eb4",
            "080e3ae4a6a04b0895ca04ce618db445",
            "84b6a69a626d400e97588e5b120debc6",
            "11527b9e366d4f1b9de65ba4be53a992",
            "05d0ab3e49be410eb6632c41847bcdcc",
            "58dadff2b011400c8bf027456cc7aa21",
            "e8b95588e44c4e5cb734c83a0ad7a812",
            "f5b4bdee011142658f8b4ff8a1d5e706",
            "cfed5df19bdc44b091afdbeb8bb5e90a",
            "351cc92ee2ad46c380a3a6b9a24d7789",
            "029629a10e014d9899a59d6225b0505e",
            "a069bcc0fb2645baaf11054c9578cbc2"
          ]
        },
        "id": "Q9LX2iCC_UlJ",
        "outputId": "5b3cebf6-63ba-4c10-b998-57bc0701362d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "Checking imported transformers version: 4.53.1\n",
            "Checking imported accelerate version: 1.8.1\n",
            "Checking imported torch version: 2.5.1+cu121\n",
            "Checking imported numpy version: 2.1.2\n",
            "Checking imported langchain version: 0.3.26\n",
            "Checking imported packaging version: 24.2\n",
            "Loading embedding model: sentence-transformers/all-MiniLM-L6-v2...\n",
            "Embedding model loaded.\n",
            "Loading ChromaDB from: /content/drive/MyDrive/vector_store/chroma_db_credi_trust...\n",
            "ChromaDB vector store loaded successfully.\n",
            "\n",
            "Prompt template defined.\n",
            "\n",
            "Loading LLM: google/flan-t5-small...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9100058264f84e7393476f8b6a534bfc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "080e3ae4a6a04b0895ca04ce618db445"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM 'google/flan-t5-small' loaded successfully.\n",
            "\n",
            "--- Starting Qualitative Evaluation ---\n",
            "\n",
            "--- Evaluating Question 1: What are common complaints related to credit cards? ---\n",
            "\n",
            "Retrieving top 5 chunks for query: 'What are common complaints related to credit cards?'...\n",
            "Retrieved 0 chunks.\n",
            "\n",
            "Sending formatted prompt to LLM...\n",
            "\n",
            "Generated Answer: Credit cards are unsecured.\n",
            "\n",
            "Top Retrieved Sources (for analysis):\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Evaluating Question 2: Tell me about issues with personal loans. ---\n",
            "\n",
            "Retrieving top 5 chunks for query: 'Tell me about issues with personal loans.'...\n",
            "Retrieved 0 chunks.\n",
            "\n",
            "Sending formatted prompt to LLM...\n",
            "\n",
            "Generated Answer: What does CrediTrust do?\n",
            "\n",
            "Top Retrieved Sources (for analysis):\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Evaluating Question 3: Are there any complaints about money transfers being delayed? ---\n",
            "\n",
            "Retrieving top 5 chunks for query: 'Are there any complaints about money transfers being delayed?'...\n",
            "Retrieved 0 chunks.\n",
            "\n",
            "Sending formatted prompt to LLM...\n",
            "\n",
            "Generated Answer: No.\n",
            "\n",
            "Top Retrieved Sources (for analysis):\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Evaluating Question 4: What problems do consumers face with Buy Now, Pay Later services? ---\n",
            "\n",
            "Retrieving top 5 chunks for query: 'What problems do consumers face with Buy Now, Pay Later services?'...\n",
            "Retrieved 0 chunks.\n",
            "\n",
            "Sending formatted prompt to LLM...\n",
            "\n",
            "Generated Answer: Consumers have problems with Buy Now, Pay Later services.\n",
            "\n",
            "Top Retrieved Sources (for analysis):\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Evaluating Question 5: Describe typical complaints about savings accounts. ---\n",
            "\n",
            "Retrieving top 5 chunks for query: 'Describe typical complaints about savings accounts.'...\n",
            "Retrieved 0 chunks.\n",
            "\n",
            "Sending formatted prompt to LLM...\n",
            "\n",
            "Generated Answer: What are some complaints about savings accounts?\n",
            "\n",
            "Top Retrieved Sources (for analysis):\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Evaluating Question 6: A customer reported a fraudulent charge on their card. What product is this related to? ---\n",
            "\n",
            "Retrieving top 5 chunks for query: 'A customer reported a fraudulent charge on their card. What product is this related to?'...\n",
            "Retrieved 0 chunks.\n",
            "\n",
            "Sending formatted prompt to LLM...\n",
            "\n",
            "Generated Answer: a credit card\n",
            "\n",
            "Top Retrieved Sources (for analysis):\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Evaluating Question 7: I sent money to a wrong account. What product category would this fall under? ---\n",
            "\n",
            "Retrieving top 5 chunks for query: 'I sent money to a wrong account. What product category would this fall under?'...\n",
            "Retrieved 0 chunks.\n",
            "\n",
            "Sending formatted prompt to LLM...\n",
            "\n",
            "Generated Answer: Consumer goods and services\n",
            "\n",
            "Top Retrieved Sources (for analysis):\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Evaluating Question 8: What is a common issue with interest rates on personal loans? ---\n",
            "\n",
            "Retrieving top 5 chunks for query: 'What is a common issue with interest rates on personal loans?'...\n",
            "Retrieved 0 chunks.\n",
            "\n",
            "Sending formatted prompt to LLM...\n",
            "\n",
            "Generated Answer: Interest rates on personal loans are high.\n",
            "\n",
            "Top Retrieved Sources (for analysis):\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Evaluating Question 9: Are there any complaints about account closures for savings accounts? ---\n",
            "\n",
            "Retrieving top 5 chunks for query: 'Are there any complaints about account closures for savings accounts?'...\n",
            "Retrieved 0 chunks.\n",
            "\n",
            "Sending formatted prompt to LLM...\n",
            "\n",
            "Generated Answer: No.\n",
            "\n",
            "Top Retrieved Sources (for analysis):\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Evaluating Question 10: What are the main concerns regarding BNPL late fees? ---\n",
            "\n",
            "Retrieving top 5 chunks for query: 'What are the main concerns regarding BNPL late fees?'...\n",
            "Retrieved 0 chunks.\n",
            "\n",
            "Sending formatted prompt to LLM...\n",
            "\n",
            "Generated Answer: BNPL late fees are expensive.\n",
            "\n",
            "Top Retrieved Sources (for analysis):\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Evaluation Table (Copy this to your report and fill in scores/comments) ---\n",
            "| Question | Generated Answer | Retrieved Sources (top 2) | Quality Score (1-5) | Comments/Analysis |\n",
            "|----------|------------------|---------------------------|---------------------|-------------------|\n",
            "| What are common complaints related to credit cards? | Credit cards are unsecured. |  |  (Manual 1-5) |  (Manual analysis) |\n",
            "| Tell me about issues with personal loans. | What does CrediTrust do? |  |  (Manual 1-5) |  (Manual analysis) |\n",
            "| Are there any complaints about money transfers being delayed? | No. |  |  (Manual 1-5) |  (Manual analysis) |\n",
            "| What problems do consumers face with Buy Now, Pay Later services? | Consumers have problems with Buy Now, Pay Later services. |  |  (Manual 1-5) |  (Manual analysis) |\n",
            "| Describe typical complaints about savings accounts. | What are some complaints about savings accounts? |  |  (Manual 1-5) |  (Manual analysis) |\n",
            "| A customer reported a fraudulent charge on their card. What product is this related to? | a credit card |  |  (Manual 1-5) |  (Manual analysis) |\n",
            "| I sent money to a wrong account. What product category would this fall under? | Consumer goods and services |  |  (Manual 1-5) |  (Manual analysis) |\n",
            "| What is a common issue with interest rates on personal loans? | Interest rates on personal loans are high. |  |  (Manual 1-5) |  (Manual analysis) |\n",
            "| Are there any complaints about account closures for savings accounts? | No. |  |  (Manual 1-5) |  (Manual analysis) |\n",
            "| What are the main concerns regarding BNPL late fees? | BNPL late fees are expensive. |  |  (Manual 1-5) |  (Manual analysis) |\n",
            "\n",
            "Task 3: RAG Core Logic and Evaluation completed. Please manually fill the evaluation table in your report.\n"
          ]
        }
      ]
    }
  ]
}